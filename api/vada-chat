export default async function handler(req, res) {
// Enable CORS
res.setHeader(‘Access-Control-Allow-Credentials’, true);
res.setHeader(‘Access-Control-Allow-Origin’, ‘*’);
res.setHeader(‘Access-Control-Allow-Methods’, ‘POST,OPTIONS’);
res.setHeader(‘Access-Control-Allow-Headers’, ‘Content-Type’);

if (req.method === ‘OPTIONS’) {
res.status(200).end();
return;
}

if (req.method !== ‘POST’) {
return res.status(405).json({ error: ‘Method not allowed’ });
}

try {
const { messages, system } = req.body;

// Get GitHub token from environment variable
const githubToken = process.env.GITHUB_TOKEN;

if (!githubToken) {
  return res.status(500).json({ 
    error: 'GitHub token not configured',
    message: 'Please add GITHUB_TOKEN to your Vercel environment variables'
  });
}

// Build messages array with system message first
const fullMessages = [
  {
    role: 'system',
    content: system
  },
  ...messages
];

// Call GitHub Models API
const response = await fetch('https://models.inference.ai.azure.com/chat/completions', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': `Bearer ${githubToken}`
  },
  body: JSON.stringify({
    model: 'gpt-4o-mini',
    messages: fullMessages,
    max_tokens: 1000,
    temperature: 0.7
  })
});

const data = await response.json();

if (!response.ok) {
  console.error('GitHub Models API error:', data);
  return res.status(response.status).json(data);
}

// Extract the message from GitHub Models response
const assistantMessage = data.choices[0].message.content;

return res.status(200).json({ 
  message: assistantMessage 
});

} catch (error) {
console.error(‘Error calling GitHub Models API:’, error);
return res.status(500).json({
error: ‘Failed to get response from AI’,
details: error.message
});
}
}